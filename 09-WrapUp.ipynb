{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0752382-c8ac-4512-8b08-c798e281f615",
   "metadata": {},
   "source": [
    "# Wrap Up\n",
    "## Some Main Points to Take Home\n",
    "### A little more effort up front...\n",
    "...can mean an immense amount of time and frustration saved later. By breaking our code into functions and defining well thought-out interfaces between the stages of our workflow, we can make our code modular, allowing us to swap functionality in and out of the workflow with ease. This modularity also fosters code-reuse making development of future projects easier and less error prone since you don't have to recode the functionality and debug it all over again. Modularity also enhances the extendability and flexibility of your code, allowing you to quickly add functionality to a specific step of the workflow without changing any of the existing code.\n",
    "### Start Simple and Iterate\n",
    "Today, we started with very simple examples of what we wanted to accomplish in our workflow and gradually added functionality until we had the what we wanted. Iteration is a key element of Byrd's data visulazation workflow and is utilized in every software engineering methodology / paradigm. Trying to build your final workflow on your first shot will exponentially increase your debug time as it makes it hard to pin down exactly where your bugs are.\n",
    "### Only Acquire What You Need\n",
    "One poor decision I see a lot of novice data researchers make when first starting to code is loading up massive DataFrames from disk when they need only a small portion of that data. Sometimes, this is unavoidable without significant effort, but as you can see with our NWM Retrospective code, we first filtered / selected the data we wanted before moving it to a pandas data structure. If you're curious, try that code without one of those select statements to narrow down the dataset spatialally or temporally. The data acquisition will take forever, if it doesn't crash Jupyter first, and even if it does work, you're now stuck with a HUGE amount of data in memory, making your machine prone to crashing due to over committed resources.\n",
    "### Use Git\n",
    "I can't stress enough, learn to trust and use Git and use it often. I can't tell you how many times researchers come to me with dozens of versions of the same code, each saved with dates, version numbers, or some other naming scheme to keep them all seperate. Managing all these versions quickly becomes overwhelming and finding older versions with the code you are looking for is extremely difficult. There's a GitHub workshop right after lunch today and if you found this workshop useful, the GitHub workshop will be a good follow-up.\n",
    "### Jupyter Notebook...\n",
    "#### ...is GREAT\n",
    "All of my software developers use it almost everyday. It allows programmers to quickly iterate on code changes and explore how Python libraries work.\n",
    "#### ...is HORRIBLE\n",
    "Jupyter's cell-based, run code in pieces paradigm is powerful for exploration, but determental to long-term code managment. You can create functions in Jupyter, as we showed to day, and use it in a modular way, but that's not really what it's designed for. By not starting with an empty environment at the top of each cell like you do when you execute Python from the terminal prompt, you can trip yourself up on duplicate naming of variables or forget what you did previously, such as filter a dataframe, and then wonder why your code isn't doing what you expect. My team ran into this exact problem last week in Jupyter and we were convinced there was a bug in a pandas function when in truth, the DataFrame we were trying to manipulate wasn't the DataFrame we thought it was because we'd already done some operations on it. Long story short, seasoned developers use Jupyter for exploration and .py files and the command line for long-term code use and workflow execution because it takes a variable, the current environment, out of the potential pool of reasons why code won't work.\n",
    "## Other Resources\n",
    "[CIROH Docs](https://docs.ciroh.org)  \n",
    "- Esp. [nwmurl Library](https://docs.ciroh.org/docs/products/dataaccess/NWMURL%20Library)\n",
    "\n",
    "[TEEHR](https://rtiinternational.github.io/teehr/index.html)  \n",
    "- [TEEHR GitHub](https://github.com/RTIInternational/teehr)  \n",
    "\n",
    "Northeast Evaluation Testbed for National Water Model Applications (NETWA)  \n",
    "- [On CIROH Docs](https://docs.ciroh.org/docs/products/netwa/)  \n",
    "- [On Github](https://github.com/CIROH-UVM)  \n",
    "- [forecast-workflow data aquisition modules](https://github.com/CIROH-UVM/forecast-workflow/tree/main/data)  \n",
    "\n",
    "[Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)  \n",
    "\n",
    "[THREDDS](https://www.unidata.ucar.edu/software/tds/)  \n",
    "\n",
    "[PyViz Tool Listing](https://pyviz.org/tools.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
